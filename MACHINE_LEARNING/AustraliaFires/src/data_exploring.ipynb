{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "from xgboost import XGBRegressor,XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "sys.path.append('C:\\\\DATA_SCIENCE')\n",
    "from sklearn import linear_model\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier \n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold, KFold, cross_val_score, GridSearchCV, cross_validate \n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, RobustScaler, Normalizer, PolynomialFeatures, MinMaxScaler\n",
    "from LIBRARY.Libreria_Folders_DVG import *\n",
    "from LIBRARY.Libreria_Pandas_DVG import *\n",
    "from LIBRARY.Libreria_ML_DVG import *\n",
    "from LIBRARY.Libreria_Maths_DVG import *\n",
    "from LIBRARY.Libreria_Graphs_DVG import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from ml_lib.to_ML import *\n",
    "from eda_lib.eda import *\n",
    "from sql_lib import sql_connector as sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sql.connector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'Tables_in_australia_fires_2': 'fire_archive_M6_96619'},\n",
       " {'Tables_in_australia_fires_2': 'fire_archive_V1_96617'},\n",
       " {'Tables_in_australia_fires_2': 'fire_nrt_M6_96619'},\n",
       " {'Tables_in_australia_fires_2': 'fire_nrt_V1_96617'},\n",
       " {'Tables_in_australia_fires_2': 'student_findings'}]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "cursor.execute(\"SHOW TABLES\") \n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM fire_archive_M6_96619\n",
    "\"\"\"\n",
    "am6 = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT *\n",
    "FROM fire_archive_V1_96617\n",
    "\"\"\"\n",
    "av1 = pd.read_sql_query(query2, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"\"\"\n",
    "SELECT *\n",
    "FROM fire_nrt_M6_96619\n",
    "\"\"\"\n",
    "nrt_m6 = pd.read_sql_query(query3, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query4 = \"\"\"\n",
    "SELECT *\n",
    "FROM fire_nrt_V1_96617\n",
    "\"\"\"\n",
    "nrt_v1 = pd.read_sql_query(query4, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "index         0\nlatitude      0\nlongitude     0\nbright_ti4    0\nscan          0\ntrack         0\nacq_date      0\nacq_time      0\nsatellite     0\ninstrument    0\nconfidence    0\nversion       0\nbright_ti5    0\nfrp           0\nfire_type     0\ndtype: int64 index         0\nlatitude      0\nlongitude     0\nbrightness    0\nscan          0\ntrack         0\nacq_date      0\nacq_time      0\nsatellite     0\ninstrument    0\nconfidence    0\nversion       0\nbright_t31    0\nfrp           0\ndaynight      0\ndtype: int64 index         0\nlatitude      0\nlongitude     0\nbright_ti4    0\nscan          0\ntrack         0\nacq_date      0\nacq_time      0\nsatellite     0\ninstrument    0\nconfidence    0\nversion       0\nbright_ti5    0\nfrp           0\ndaynight      0\ndtype: int64\nindex         0\nlatitude      0\nlongitude     0\nbrightness    0\nscan          0\ntrack         0\nacq_date      0\nacq_time      0\nsatellite     0\ninstrument    0\nconfidence    0\nversion       0\nbright_t31    0\nfrp           0\ndaynight      0\nfire_type     0\ndtype: int64 None\n"
     ]
    }
   ],
   "source": [
    "print(am6.isnull().sum(), print(av1.isnull().sum(), nrt_m6.isnull().sum(), nrt_v1.isnull().sum()))  #no Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((36011, 16), (184778, 15), (183593, 15), (956257, 15))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "am6.shape, av1.shape, nrt_m6.shape, nrt_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Index(['fire_type'], dtype='object'), Index(['fire_type'], dtype='object'))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "am6.columns.difference(nrt_m6.columns), av1.columns.difference(nrt_v1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['bright_t31', 'brightness', 'daynight'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "am6.columns.difference(av1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "global le                                           #asignamos el mismo lable encoder para todos los dataframe para homogeneizar\n",
    "def encoder2(df):\n",
    "    cat_cols = (df.dtypes ==\"object\")\n",
    "    object_cols = list(cat_cols[cat_cols].index)\n",
    "    print(\"Categorical variables:\")\n",
    "    print(object_cols)\n",
    "    for col in object_cols:\n",
    "        df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Categorical variables:\n",
      "['latitude', 'acq_date', 'satellite', 'instrument', 'daynight']\n",
      "Categorical variables:\n",
      "['latitude', 'acq_date', 'satellite', 'instrument', 'confidence']\n",
      "Categorical variables:\n",
      "['latitude', 'acq_date', 'satellite', 'instrument', 'version', 'daynight']\n",
      "Categorical variables:\n",
      "['latitude', 'acq_date', 'satellite', 'instrument', 'confidence', 'version', 'daynight']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "encoder2(am6), encoder2(av1), encoder2(nrt_m6), encoder2(nrt_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "latitude      0.037375\nlongitude     0.001074\nbright_ti4   -0.032832\nscan         -0.008146\ntrack        -0.011568\nacq_date      0.012548\nacq_time      0.028850\nsatellite          NaN\ninstrument         NaN\nconfidence    0.021982\nversion            NaN\nbright_ti5   -0.044027\nfrp          -0.018583\nfire_type     1.000000\nName: fire_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target_corr(av1, 'fire_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "latitude      0.063429\nlongitude     0.008290\nbrightness   -0.052514\nscan         -0.023828\ntrack        -0.024296\nacq_date     -0.004873\nacq_time      0.001431\nsatellite     0.021261\ninstrument         NaN\nconfidence   -0.039003\nversion            NaN\nbright_t31   -0.053730\nfrp          -0.035229\ndaynight      0.007317\nfire_type     1.000000\nName: fire_type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target_corr(am6, 'fire_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "av1 = column_renamer(av1, ['bright_ti4', 'bright_ti5'], ['brightness', 'bright_t31'])\n",
    "nrt_v1 = column_renamer(nrt_v1, ['bright_ti4', 'bright_ti5'], ['brightness', 'bright_t31'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "am6.drop(columns='daynight', inplace=True)\n",
    "nrt_m6.drop(columns='daynight', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(av1, am6, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = targeter(df, 'fire_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train , y_test = train_test_split(X, y, test_size=0.2, random_state=151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "For evaluating multiple scores, use sklearn.model_selection.cross_validate instead. ['mean_square_error'] was passed.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-6979083b8784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'GRID-{name}.sav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     else:\"\"\"  # Para cualquier otro caso\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'GRID3-{name}.sav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[1;31m# To ensure multimetric format is not supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    453\u001b[0m                 % estimator)\n\u001b[0;32m    454\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m         raise ValueError(\"For evaluating multiple scores, use \"\n\u001b[0m\u001b[0;32m    456\u001b[0m                          \u001b[1;34m\"sklearn.model_selection.cross_validate instead. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m                          \"{0} was passed.\".format(scoring))\n",
      "\u001b[1;31mValueError\u001b[0m: For evaluating multiple scores, use sklearn.model_selection.cross_validate instead. ['mean_square_error'] was passed."
     ]
    }
   ],
   "source": [
    "seed = 4600\n",
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('PR', LinearRegression()))\n",
    "models.append(('RFR', RandomForestClassifier()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = ['mean_square_error']\n",
    "for name, model in models:\n",
    "    \n",
    "    kfold = KFold(n_splits=4, shuffle=True, random_state=seed)\n",
    "\n",
    "    \"\"\"if name == 'PR':  # Por utilizar el modelo del polinomio\n",
    "        poly_reg = PolynomialFeatures(degree = 4)\n",
    "        X_poly = poly_reg.fit_transform(X_train)\n",
    "        cv_results = cross_val_score(model, X_poly, y_train.ravel(), cv=kfold, scoring=scoring)\n",
    "        pickle.dump(model, open(f'GRID-{name}.sav', 'wb'))\n",
    "    else:\"\"\"  # Para cualquier otro caso\n",
    "    cv_results = cross_val_score(model, X_train, y_train.ravel(), cv=kfold, scoring=scoring)\n",
    "    pickle.dump(model, open(f'GRID3-{name}.sav', 'wb'))\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# boxplot algorithm comparison \n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[('classifier', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "logistic_params = {\n",
    "    'classifier': [LogisticRegression(warm_start=True)],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__C': np.logspace(0, 4, 10)\n",
    "    }\n",
    "\n",
    "random_forest_params = {\n",
    "    'classifier': [RandomForestClassifier(warm_start=True)],\n",
    "    'classifier__n_estimators': [10, 100, 1000],\n",
    "    'classifier__max_features': [1, 2, 3]\n",
    "    }\n",
    "    \n",
    "xgboost_params = {\n",
    "    'classifier' : [XGBClassifier(warm_start=True)],\n",
    "    'classifier__learning_rate'  : [0.10, 0.15, 0.2],\n",
    "    'classifier__max_depth'        : [4, 5, 7],\n",
    "    'classifier__min_child_weight' : [ 3, 5, 7],\n",
    "    'classifier__gamma'            : [ 0.1, 0.2, 0.3],\n",
    "    'classifier__colsample_bytree' : [ 0.4, 0.5, 0.7]}\n",
    "\n",
    "# hypertuning \n",
    "# Create space of candidate learning algorithms and their hyperparameters\n",
    "search_space = [\n",
    "    logistic_params,\n",
    "    random_forest_params,\n",
    "    xgboost_params\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "# Create grid search \n",
    "clf = GridSearchCV(estimator=pipe, param_grid=search_space, cv=cv, verbose=0, n_jobs=-2)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "# View best model\n",
    "separator = \"\\n############################\\n\"\n",
    "print(separator)\n",
    "print(\"best estimator:\", best_model.best_estimator_.get_params()['classifier'])\n",
    "print(separator)\n",
    "print(\"clf.best_params_\", clf.best_params_)\n",
    "print(separator)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"clf.best_score\", clf.best_score_)\n",
    "#SAVE MODEL\n",
    "# save the model to disk\n",
    "filename = 'hyperXGB6.sav'\n",
    "success = best_model.best_estimator_.get_params()\n",
    "pickle.dump(success, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ]
}