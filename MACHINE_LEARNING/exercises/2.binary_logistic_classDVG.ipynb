{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. \n",
    "\n",
    "En el archivo \"logistic_regression_df_class\" hemos visto un ejemplo multiclase. Elimina del dataframe todas las filas que se correspondan con la clase valor \"1\".\n",
    "\n",
    "Ahora, realiza el ejercicio con el nuevo dataframe:\n",
    "\n",
    "- ¿Se mejora la precisión del algoritmo con dos clases? ¿por qué?\n",
    "\n",
    "### Sí. Por que los target menos numerosos hacen más fácil elegir.\n",
    "\n",
    "LogisticRegression() es una clase que tiene varios parámetros de entrada. Investiga (modifica, prueba) los argumentos y comenta si modificando algunas de ellas se mejora el porcentaje de acierto del problema.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/usuarios_win_mac_lin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df.clase == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     duracion  paginas  acciones  valor  clase\n",
       "0         7.0        2         4      8      2\n",
       "1        21.0        2         6      6      2\n",
       "2        57.0        2         4      4      2\n",
       "3       101.0        3         6     12      2\n",
       "4       109.0        2         6     12      2\n",
       "..        ...      ...       ...    ...    ...\n",
       "165      13.0        1         7     42      0\n",
       "166      12.0        1         2      6      0\n",
       "167      13.0        1         3      9      0\n",
       "168      13.0        1         7     28      0\n",
       "169      12.0        1         6     18      0\n",
       "\n",
       "[130 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duracion</th>\n      <th>paginas</th>\n      <th>acciones</th>\n      <th>valor</th>\n      <th>clase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21.0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>6</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>57.0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>101.0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>12</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>109.0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>12</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>13.0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>42</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>12.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>13.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>13.0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>28</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>12.0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>18</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>130 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[df.columns.difference(['clase'])])\n",
    "y = np.array(df['clase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.20, random_state=343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "lgr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9519230769230769 -- 0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "print(lgr.score(X_train, y_train),'--', lgr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Score newton-cg 0.9519230769230769 \n",
      " Test Score newton-cg 0.9615384615384616\n",
      "----------------------\n",
      "Train Score lbfgs 0.9519230769230769 \n",
      " Test Score lbfgs 0.9615384615384616\n",
      "----------------------\n",
      "Train Score liblinear 0.9519230769230769 \n",
      " Test Score liblinear 0.9615384615384616\n",
      "----------------------\n",
      "Train Score sag 0.9519230769230769 \n",
      " Test Score sag 0.9615384615384616\n",
      "----------------------\n",
      "Train Score saga 0.9519230769230769 \n",
      " Test Score saga 0.9615384615384616\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "for x in solvers:                           #trying different solvers (algorithm used in the optimisation problem, default is lbfgs)\n",
    "    lg = LogisticRegression(solver=x)\n",
    "    lg.fit(X_train, y_train)\n",
    "    print('Train Score', x, lgr.score(X_train, y_train),'\\n', 'Test Score', x, lgr.score(X_test, y_test))\n",
    "    print('----------------------')"
   ]
  }
 ]
}